# Spark란
대규모 분산 데이터 처리를 하기 위한 설계된 엔진
Spark SQL, MLLib, Streaming, GraphX 등의 API들로 이루어지고 있다.
다음과 같은 특성이 있다.
- 속도
- 사용 편리성
- 모듈성
- 확장성

## 속도
- 멀티스레드와 병렬 처리를 지원하는 유닉스 기반 OS를 포함함.
- 비순환 그래프(DAG)로 구성됨. DAG의 스케쥴러와 최적화 모듈을 각각의 task로 분배하여 워커 노드 위에서 병렬 수행될 수 있도록 해준다.
- 최적화된 코드를 생성해냄
- 중간 결과를 메모리에 저장하여 디스크 I/O를 제한적으로 사용

## 사용 편리성
RDD(Resilent distributed dataset, 분산 데이터 세트)라는 단순한 논리 자료구조를 구축.
트랜스포메이션, 액션을 제공함으로써 편한 언어로 애플리케이션 생성 가능

## 확장성
수많은 데이터 소스에서 데이터를 읽을 수가 있다.
ex) elastic mysql kafka delta_lake redis mongodb cassandra hvase hdfs postgresql

# Spark 애플리케이션 개념
## 드라이버
드라이버는 SparkSession 객체를 통해 executor와 클러스터 매니저에 접근한다.
드라이버는 클러스터 매니저에게 필요한 자원을 요청하고, 작업을 DAG 형태로 변환하고 실행 단위를 task로 나누어 executor에 분배한다.

## SparkSession
SparkSession은 연산과 데이터에 대한 통합 연결 채널이다.
셸에서는 스파크 드라이버가 SparkSession을 제공하지만, 스파크 애플리케이션에서는 직접 생성해야한다.

## job, stage, task
job은 spark action(save, collect)에 대한 응답으로 생성하는 task로 이루어진 병렬 연산이다.
stage은 다수의 task 모음이다. 넓은 트랜스포메이션 단위가 된다.
task는 executor로 보내는 작업 실행의 기본적인 단위

## 매니저, executor
클러스터 매니저는 클러스터에서 자원을 관리 및 할당한다. Yarn, Mesos, Kubernetes 등이 있다.
Spark executor는 클러스터의 각 worker node에서 동작한다.

